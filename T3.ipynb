{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhruv-Sharma01/ES335_Andrew_NG/blob/main/T3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TGH8ZQmKyvU7",
        "outputId": "07725af0-8597-435d-f987-0ea72da7bd44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.1.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-core<0.3.0,>=0.2.26 (from langchain_groq)\n",
            "  Downloading langchain_core-0.2.35-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (6.0.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.26->langchain_groq)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.75 (from langchain-core<0.3.0,>=0.2.26->langchain_groq)\n",
            "  Downloading langsmith-0.1.106-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (24.1)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-core<0.3.0,>=0.2.26->langchain_groq)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain_groq)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m983.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (2.0.7)\n",
            "Downloading langchain_groq-0.1.9-py3-none-any.whl (14 kB)\n",
            "Downloading groq-0.10.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.35-py3-none-any.whl (394 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langsmith-0.1.106-py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, orjson, jsonpointer, h11, jsonpatch, httpcore, httpx, langsmith, groq, langchain-core, langchain_groq\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed groq-0.10.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.2.35 langchain_groq-0.1.9 langsmith-0.1.106 orjson-3.10.7 tenacity-8.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNzBmVL2x-yw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from langchain_groq.chat_models import ChatGroq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QTXy9fOx-yy"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "Groq_token=userdata.get('GROQ_API_KEY')\n",
        "\n",
        "\n",
        "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwExfIB_x-yz",
        "outputId": "9fe3a474-d6ab-4fa7-c1dd-01c287645a2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape:  (7352, 561)\n",
            "y shape:  (7352, 1)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Reading the data from the text file into a pandas DataFrame\n",
        "X_train = pd.read_csv(\n",
        "    '/content/X_train.txt',\n",
        "    sep='\\s+', # white space as delimiter\n",
        "    header=None  # No header row in the file\n",
        ")\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(\"X shape: \",X_train.shape)\n",
        "\n",
        "y_train=pd.read_csv(\n",
        "    '/content/y_train.txt',\n",
        "    header=None\n",
        ")\n",
        "\n",
        "print(\"y shape: \",y_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "muPwxbGyx-y1",
        "outputId": "aec63b92-c12f-414b-cd02-eeea724ed797"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6    \\\n",
              "0     0.257178 -0.023285 -0.014654 -0.938404 -0.920091 -0.667683 -0.952501   \n",
              "1     0.286027 -0.013163 -0.119083 -0.975415 -0.967458 -0.944958 -0.986799   \n",
              "2     0.275485 -0.026050 -0.118152 -0.993819 -0.969926 -0.962748 -0.994403   \n",
              "3     0.270298 -0.032614 -0.117520 -0.994743 -0.973268 -0.967091 -0.995274   \n",
              "4     0.274833 -0.027848 -0.129527 -0.993852 -0.967445 -0.978295 -0.994111   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "2942  0.310155 -0.053391 -0.099109 -0.287866 -0.140589 -0.215088 -0.356083   \n",
              "2943  0.363385 -0.039214 -0.105915 -0.305388  0.028148 -0.196373 -0.373540   \n",
              "2944  0.349966  0.030077 -0.115788 -0.329638 -0.042143 -0.250181 -0.388017   \n",
              "2945  0.237594  0.018467 -0.096499 -0.323114 -0.229775 -0.207574 -0.392380   \n",
              "2946  0.153627 -0.018437 -0.137018 -0.330046 -0.195253 -0.164339 -0.430974   \n",
              "\n",
              "           7         8         9    ...       551       552       553  \\\n",
              "0    -0.925249 -0.674302 -0.894088  ...  0.071645 -0.330370 -0.705974   \n",
              "1    -0.968401 -0.945823 -0.894088  ... -0.401189 -0.121845 -0.594944   \n",
              "2    -0.970735 -0.963483 -0.939260  ...  0.062891 -0.190422 -0.640736   \n",
              "3    -0.974471 -0.968897 -0.938610  ...  0.116695 -0.344418 -0.736124   \n",
              "4    -0.965953 -0.977346 -0.938610  ... -0.121711 -0.534685 -0.846595   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "2942 -0.148775 -0.232057  0.185361  ...  0.074472 -0.376278 -0.750809   \n",
              "2943 -0.030036 -0.270237  0.185361  ...  0.101859 -0.320418 -0.700274   \n",
              "2944 -0.133257 -0.347029  0.007471  ... -0.066249 -0.118854 -0.467179   \n",
              "2945 -0.279610 -0.289477  0.007471  ... -0.046467 -0.205445 -0.617737   \n",
              "2946 -0.218295 -0.229933 -0.111527  ... -0.010386 -0.072237 -0.436940   \n",
              "\n",
              "           554       555       556       557       558       559       560  \n",
              "0     0.006462  0.162920 -0.825886  0.271151 -0.720009  0.276801 -0.057978  \n",
              "1    -0.083495  0.017500 -0.434375  0.920593 -0.698091  0.281343 -0.083898  \n",
              "2    -0.034956  0.202302  0.064103  0.145068 -0.702771  0.280083 -0.079346  \n",
              "3    -0.017067  0.154438  0.340134  0.296407 -0.698954  0.284114 -0.077108  \n",
              "4    -0.002223 -0.040046  0.736715 -0.118545 -0.692245  0.290722 -0.073857  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "2942 -0.337422  0.346295  0.884904 -0.698885 -0.651732  0.274627  0.184784  \n",
              "2943 -0.736701 -0.372889 -0.657421  0.322549 -0.655181  0.273578  0.182412  \n",
              "2944 -0.181560  0.088574  0.696663  0.363139 -0.655357  0.274479  0.181184  \n",
              "2945  0.444558 -0.819188  0.929294 -0.008398 -0.659719  0.264782  0.187563  \n",
              "2946  0.598808 -0.287951  0.876030 -0.024965 -0.660080  0.263936  0.188103  \n",
              "\n",
              "[2947 rows x 561 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e70466e-1b41-4b34-9a19-4660c8d339fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>551</th>\n",
              "      <th>552</th>\n",
              "      <th>553</th>\n",
              "      <th>554</th>\n",
              "      <th>555</th>\n",
              "      <th>556</th>\n",
              "      <th>557</th>\n",
              "      <th>558</th>\n",
              "      <th>559</th>\n",
              "      <th>560</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.257178</td>\n",
              "      <td>-0.023285</td>\n",
              "      <td>-0.014654</td>\n",
              "      <td>-0.938404</td>\n",
              "      <td>-0.920091</td>\n",
              "      <td>-0.667683</td>\n",
              "      <td>-0.952501</td>\n",
              "      <td>-0.925249</td>\n",
              "      <td>-0.674302</td>\n",
              "      <td>-0.894088</td>\n",
              "      <td>...</td>\n",
              "      <td>0.071645</td>\n",
              "      <td>-0.330370</td>\n",
              "      <td>-0.705974</td>\n",
              "      <td>0.006462</td>\n",
              "      <td>0.162920</td>\n",
              "      <td>-0.825886</td>\n",
              "      <td>0.271151</td>\n",
              "      <td>-0.720009</td>\n",
              "      <td>0.276801</td>\n",
              "      <td>-0.057978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.286027</td>\n",
              "      <td>-0.013163</td>\n",
              "      <td>-0.119083</td>\n",
              "      <td>-0.975415</td>\n",
              "      <td>-0.967458</td>\n",
              "      <td>-0.944958</td>\n",
              "      <td>-0.986799</td>\n",
              "      <td>-0.968401</td>\n",
              "      <td>-0.945823</td>\n",
              "      <td>-0.894088</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.401189</td>\n",
              "      <td>-0.121845</td>\n",
              "      <td>-0.594944</td>\n",
              "      <td>-0.083495</td>\n",
              "      <td>0.017500</td>\n",
              "      <td>-0.434375</td>\n",
              "      <td>0.920593</td>\n",
              "      <td>-0.698091</td>\n",
              "      <td>0.281343</td>\n",
              "      <td>-0.083898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.275485</td>\n",
              "      <td>-0.026050</td>\n",
              "      <td>-0.118152</td>\n",
              "      <td>-0.993819</td>\n",
              "      <td>-0.969926</td>\n",
              "      <td>-0.962748</td>\n",
              "      <td>-0.994403</td>\n",
              "      <td>-0.970735</td>\n",
              "      <td>-0.963483</td>\n",
              "      <td>-0.939260</td>\n",
              "      <td>...</td>\n",
              "      <td>0.062891</td>\n",
              "      <td>-0.190422</td>\n",
              "      <td>-0.640736</td>\n",
              "      <td>-0.034956</td>\n",
              "      <td>0.202302</td>\n",
              "      <td>0.064103</td>\n",
              "      <td>0.145068</td>\n",
              "      <td>-0.702771</td>\n",
              "      <td>0.280083</td>\n",
              "      <td>-0.079346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.270298</td>\n",
              "      <td>-0.032614</td>\n",
              "      <td>-0.117520</td>\n",
              "      <td>-0.994743</td>\n",
              "      <td>-0.973268</td>\n",
              "      <td>-0.967091</td>\n",
              "      <td>-0.995274</td>\n",
              "      <td>-0.974471</td>\n",
              "      <td>-0.968897</td>\n",
              "      <td>-0.938610</td>\n",
              "      <td>...</td>\n",
              "      <td>0.116695</td>\n",
              "      <td>-0.344418</td>\n",
              "      <td>-0.736124</td>\n",
              "      <td>-0.017067</td>\n",
              "      <td>0.154438</td>\n",
              "      <td>0.340134</td>\n",
              "      <td>0.296407</td>\n",
              "      <td>-0.698954</td>\n",
              "      <td>0.284114</td>\n",
              "      <td>-0.077108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.274833</td>\n",
              "      <td>-0.027848</td>\n",
              "      <td>-0.129527</td>\n",
              "      <td>-0.993852</td>\n",
              "      <td>-0.967445</td>\n",
              "      <td>-0.978295</td>\n",
              "      <td>-0.994111</td>\n",
              "      <td>-0.965953</td>\n",
              "      <td>-0.977346</td>\n",
              "      <td>-0.938610</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.121711</td>\n",
              "      <td>-0.534685</td>\n",
              "      <td>-0.846595</td>\n",
              "      <td>-0.002223</td>\n",
              "      <td>-0.040046</td>\n",
              "      <td>0.736715</td>\n",
              "      <td>-0.118545</td>\n",
              "      <td>-0.692245</td>\n",
              "      <td>0.290722</td>\n",
              "      <td>-0.073857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2942</th>\n",
              "      <td>0.310155</td>\n",
              "      <td>-0.053391</td>\n",
              "      <td>-0.099109</td>\n",
              "      <td>-0.287866</td>\n",
              "      <td>-0.140589</td>\n",
              "      <td>-0.215088</td>\n",
              "      <td>-0.356083</td>\n",
              "      <td>-0.148775</td>\n",
              "      <td>-0.232057</td>\n",
              "      <td>0.185361</td>\n",
              "      <td>...</td>\n",
              "      <td>0.074472</td>\n",
              "      <td>-0.376278</td>\n",
              "      <td>-0.750809</td>\n",
              "      <td>-0.337422</td>\n",
              "      <td>0.346295</td>\n",
              "      <td>0.884904</td>\n",
              "      <td>-0.698885</td>\n",
              "      <td>-0.651732</td>\n",
              "      <td>0.274627</td>\n",
              "      <td>0.184784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2943</th>\n",
              "      <td>0.363385</td>\n",
              "      <td>-0.039214</td>\n",
              "      <td>-0.105915</td>\n",
              "      <td>-0.305388</td>\n",
              "      <td>0.028148</td>\n",
              "      <td>-0.196373</td>\n",
              "      <td>-0.373540</td>\n",
              "      <td>-0.030036</td>\n",
              "      <td>-0.270237</td>\n",
              "      <td>0.185361</td>\n",
              "      <td>...</td>\n",
              "      <td>0.101859</td>\n",
              "      <td>-0.320418</td>\n",
              "      <td>-0.700274</td>\n",
              "      <td>-0.736701</td>\n",
              "      <td>-0.372889</td>\n",
              "      <td>-0.657421</td>\n",
              "      <td>0.322549</td>\n",
              "      <td>-0.655181</td>\n",
              "      <td>0.273578</td>\n",
              "      <td>0.182412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2944</th>\n",
              "      <td>0.349966</td>\n",
              "      <td>0.030077</td>\n",
              "      <td>-0.115788</td>\n",
              "      <td>-0.329638</td>\n",
              "      <td>-0.042143</td>\n",
              "      <td>-0.250181</td>\n",
              "      <td>-0.388017</td>\n",
              "      <td>-0.133257</td>\n",
              "      <td>-0.347029</td>\n",
              "      <td>0.007471</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.066249</td>\n",
              "      <td>-0.118854</td>\n",
              "      <td>-0.467179</td>\n",
              "      <td>-0.181560</td>\n",
              "      <td>0.088574</td>\n",
              "      <td>0.696663</td>\n",
              "      <td>0.363139</td>\n",
              "      <td>-0.655357</td>\n",
              "      <td>0.274479</td>\n",
              "      <td>0.181184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2945</th>\n",
              "      <td>0.237594</td>\n",
              "      <td>0.018467</td>\n",
              "      <td>-0.096499</td>\n",
              "      <td>-0.323114</td>\n",
              "      <td>-0.229775</td>\n",
              "      <td>-0.207574</td>\n",
              "      <td>-0.392380</td>\n",
              "      <td>-0.279610</td>\n",
              "      <td>-0.289477</td>\n",
              "      <td>0.007471</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.046467</td>\n",
              "      <td>-0.205445</td>\n",
              "      <td>-0.617737</td>\n",
              "      <td>0.444558</td>\n",
              "      <td>-0.819188</td>\n",
              "      <td>0.929294</td>\n",
              "      <td>-0.008398</td>\n",
              "      <td>-0.659719</td>\n",
              "      <td>0.264782</td>\n",
              "      <td>0.187563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2946</th>\n",
              "      <td>0.153627</td>\n",
              "      <td>-0.018437</td>\n",
              "      <td>-0.137018</td>\n",
              "      <td>-0.330046</td>\n",
              "      <td>-0.195253</td>\n",
              "      <td>-0.164339</td>\n",
              "      <td>-0.430974</td>\n",
              "      <td>-0.218295</td>\n",
              "      <td>-0.229933</td>\n",
              "      <td>-0.111527</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.010386</td>\n",
              "      <td>-0.072237</td>\n",
              "      <td>-0.436940</td>\n",
              "      <td>0.598808</td>\n",
              "      <td>-0.287951</td>\n",
              "      <td>0.876030</td>\n",
              "      <td>-0.024965</td>\n",
              "      <td>-0.660080</td>\n",
              "      <td>0.263936</td>\n",
              "      <td>0.188103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2947 rows × 561 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e70466e-1b41-4b34-9a19-4660c8d339fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2e70466e-1b41-4b34-9a19-4660c8d339fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2e70466e-1b41-4b34-9a19-4660c8d339fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-025fe1ba-4c75-4dfe-8665-123b5181d508\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-025fe1ba-4c75-4dfe-8665-123b5181d508')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-025fe1ba-4c75-4dfe-8665-123b5181d508 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_347bbabd-e6db-41a7-a0ee-1a833538d6c4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_347bbabd-e6db-41a7-a0ee-1a833538d6c4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_test"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "X_test = pd.read_csv(\n",
        "    '/content/X_test.txt',\n",
        "    sep='\\s+', # white space as delimiter\n",
        "    header=None  # No header row in the file\n",
        ")\n",
        "\n",
        "y_test=pd.read_csv(\n",
        "    '/content/y_test.txt',\n",
        "    header=None\n",
        ")\n",
        "\n",
        "X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oagDbso6x-y1"
      },
      "source": [
        "## Zero Shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDaseRF0x-y2",
        "outputId": "88919a87-8f12-4c2b-c393-3ac2293053bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 2913\n",
            "LLM Classification: A classification task!\n",
            "\n",
            "To classify the accelerometer data into a human activity, I'll need to analyze the patterns and features present in the data. Since I don't have any additional information about the data, such as the sampling rate, sensor orientation, or the specific activities being monitored, I'll have to rely on general machine learning techniques to make an educated guess.\n",
            "\n",
            "After examining the data, I notice that it appears to be a time series signal with 560 samples. The values range from -1.0 to 1.0, which suggests that the data might be normalized or standardized in some way.\n",
            "\n",
            "To classify the data, I'll use a simple machine learning approach. I'll extract some basic features from the time series signal, such as:\n",
            "\n",
            "1. Mean absolute value\n",
            "2. Standard deviation\n",
            "3. Variance\n",
            "4. Root mean square (RMS) value\n",
            "5. Peak-to-peak amplitude\n",
            "6. Autocorrelation coefficients (up to lag 10)\n",
            "\n",
            "Using these features, I'll train a simple classifier, such as a decision tree or a random forest, to predict the activity label.\n",
            "\n",
            "After training the model, I'll use it to predict the label for the provided data.\n",
            "\n",
            "**Predicted Label:** Walking\n",
            "\n",
            "Please note that this is a rough estimate, and the accuracy of the prediction depends on various factors, such as the quality of the data, the choice of features, and the performance of the classifier. In a real-world scenario, it's essential to collect more data, experiment with different features and models, and evaluate the performance of the classifier using metrics such as accuracy, precision, recall, and F1-score.\n",
            "Actual Label: SITTING\n",
            "\n",
            "==================================================\n",
            "\n",
            "Index: 2451\n",
            "LLM Classification: A classification task!\n",
            "\n",
            "To classify the accelerometer data into a human activity, I'll need to analyze the patterns and features present in the data. Since I don't have any additional information about the data, such as the sampling rate, sensor orientation, or the specific activities being monitored, I'll have to rely on general machine learning techniques to make an educated guess.\n",
            "\n",
            "After examining the data, I notice that it appears to be a time series signal with 560 samples. The values range from -1 to 1, which suggests that the data might be normalized or standardized in some way.\n",
            "\n",
            "To classify the data, I'll use a simple machine learning approach. I'll extract some basic features from the time series signal, such as:\n",
            "\n",
            "1. Mean\n",
            "2. Standard deviation\n",
            "3. Variance\n",
            "4. Skewness\n",
            "5. Kurtosis\n",
            "6. Peak-to-peak amplitude\n",
            "7. Root mean square (RMS) value\n",
            "\n",
            "Using these features, I'll train a simple classifier, such as a decision tree or a random forest, to predict the activity label.\n",
            "\n",
            "After training the model, I'll use it to predict the label for the provided data.\n",
            "\n",
            "**Predicted Label:** Walking\n",
            "\n",
            "Please note that this is a rough estimate, and the accuracy of the prediction depends on various factors, such as the quality of the data, the choice of features, and the performance of the classifier. In a real-world scenario, it's essential to collect more data, experiment with different features and models, and evaluate the performance of the classifier using metrics such as accuracy, precision, recall, and F1-score.\n",
            "Actual Label: LAYING\n",
            "\n",
            "==================================================\n",
            "\n",
            "Index: 4151\n",
            "LLM Classification: A classification task!\n",
            "\n",
            "To classify the accelerometer data into a human activity, I'll need to analyze the patterns and features present in the data. Since I don't have any additional information about the data, such as the sampling rate, sensor orientation, or the specific activities being monitored, I'll have to rely on general machine learning techniques to make an educated guess.\n",
            "\n",
            "After examining the data, I notice that it appears to be a time series signal with 500 data points. The values range from approximately -1 to 1, which suggests that the data might be normalized or standardized in some way.\n",
            "\n",
            "To classify the data, I'll use a simple machine learning approach. I'll extract some basic features from the data, such as:\n",
            "\n",
            "1. Mean absolute value\n",
            "2. Standard deviation\n",
            "3. Variance\n",
            "4. Skewness\n",
            "5. Kurtosis\n",
            "6. Peak-to-peak amplitude\n",
            "7. Root mean square (RMS) value\n",
            "\n",
            "Using these features, I'll train a simple classifier, such as a decision tree or a random forest, to predict the activity label.\n",
            "\n",
            "After training the model, I'll use it to predict the label for the provided data.\n",
            "\n",
            "**Predicted Label:** Walking\n",
            "\n",
            "Please note that this is a rough estimate, and the accuracy of the prediction depends on various factors, such as the quality of the data, the choice of features, and the performance of the classifier. In a real-world scenario, it's essential to collect more data, experiment with different features and models, and evaluate the performance of the classifier using metrics such as accuracy, precision, recall, and F1-score.\n",
            "Actual Label: WALKING_UPSTAIRS\n",
            "\n",
            "==================================================\n",
            "\n",
            "Index: 2399\n",
            "LLM Classification: A classification task!\n",
            "\n",
            "To classify the accelerometer data into a human activity, I'll need to analyze the patterns and features present in the data. Since I don't have any additional information about the data, such as the sampling rate, sensor orientation, or the specific activities being monitored, I'll have to rely on general machine learning techniques to make an educated guess.\n",
            "\n",
            "After examining the data, I notice that it appears to be a time series signal with 560 samples. The values range from -1.0 to 1.0, which suggests that the data might be normalized or standardized in some way.\n",
            "\n",
            "To classify the data, I'll use a simple machine learning approach. I'll extract some basic features from the time series signal, such as:\n",
            "\n",
            "1. Mean\n",
            "2. Standard deviation\n",
            "3. Variance\n",
            "4. Skewness\n",
            "5. Kurtosis\n",
            "6. Peak-to-peak amplitude\n",
            "7. Root mean square (RMS) value\n",
            "\n",
            "These features can help capture the overall characteristics of the signal, such as its central tendency, dispersion, and shape.\n",
            "\n",
            "Using these features, I'll train a simple classifier, such as a decision tree or a random forest, to predict the activity label. Since I don't have any labeled data, I'll have to rely on my intuition and general knowledge of human activities to make an educated guess.\n",
            "\n",
            "After analyzing the features, I'm going to take a wild guess and predict that the activity label is:\n",
            "\n",
            "**Label: Walking**\n",
            "\n",
            "My reasoning is based on the following observations:\n",
            "\n",
            "* The signal appears to have a relatively consistent pattern, with some oscillations and peaks, which might indicate a repetitive motion like walking.\n",
            "* The mean and standard deviation of the signal are relatively small, which could suggest a low-to-moderate intensity activity like walking.\n",
            "* The skewness and kurtosis of the signal are not extreme, which might indicate a relatively symmetrical and bell-shaped distribution, consistent with a walking pattern.\n",
            "\n",
            "Please note that this is a highly uncertain prediction, and the actual activity label could be anything! If you have more information about the data or the specific activities being monitored, I'd be happy to refine my prediction.\n",
            "Actual Label: STANDING\n",
            "\n",
            "==================================================\n",
            "\n",
            "Index: 6195\n",
            "LLM Classification: A classification task!\n",
            "\n",
            "To classify the accelerometer data into a human activity, I'll need to analyze the patterns and features present in the data. Since I don't have any additional information about the data, such as the sampling rate, sensor orientation, or the specific activities being monitored, I'll have to rely on general machine learning techniques to make an educated guess.\n",
            "\n",
            "After examining the data, I notice that it appears to be a time series signal with 560 data points. The values range from -1 to 1, which suggests that the data might be normalized or scaled.\n",
            "\n",
            "To classify the data, I'll use a simple machine learning approach. I'll extract some basic features from the data, such as:\n",
            "\n",
            "1. Mean absolute value\n",
            "2. Standard deviation\n",
            "3. Variance\n",
            "4. Root mean square (RMS) value\n",
            "5. Peak-to-peak amplitude\n",
            "\n",
            "Using these features, I'll train a simple classifier, such as a decision tree or a random forest, to predict the activity label.\n",
            "\n",
            "After training the model, I'll make a prediction based on the extracted features.\n",
            "\n",
            "**Predicted Label:** Walking\n",
            "\n",
            "Please note that this is a rough estimate, and the accuracy of the prediction depends on various factors, such as the quality of the data, the choice of features, and the complexity of the classification model. If you have more information about the data or the specific activities being monitored, I can refine my approach to improve the accuracy of the prediction.\n",
            "Actual Label: WALKING_DOWNSTAIRS\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the activity labels\n",
        "activity_labels = {\n",
        "    1: \"WALKING\",\n",
        "    2: \"WALKING_UPSTAIRS\",\n",
        "    3: \"WALKING_DOWNSTAIRS\",\n",
        "    4: \"SITTING\",\n",
        "    5: \"STANDING\",\n",
        "    6: \"LAYING\"\n",
        "}\n",
        "\n",
        "# Generate random indexes\n",
        "indexes = np.random.randint(0, len(X_train), size=5)\n",
        "\n",
        "for index in indexes:\n",
        "    # Convert the row to a string representation\n",
        "    data_str = X_train.iloc[index].to_string()\n",
        "\n",
        "    # Create the query for the model\n",
        "    query = f\"Classify the following accelerometer data into the correct human activity: {data_str}. Print predicted label as follows: Label: <predicted_label>\"\n",
        "\n",
        "    # Initialize and use the language model\n",
        "    model_name = \"llama3-70b\"  # Model name\n",
        "    llm = ChatGroq(model=groq_models[model_name], api_key=Groq_token, temperature=0)\n",
        "    answer = llm.invoke(query)\n",
        "\n",
        "    # Get the actual label and its corresponding activity name\n",
        "    actual_label = y_train.iloc[index].values[0]\n",
        "    actual_activity = activity_labels[actual_label]\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Index: {index}\")\n",
        "    print(f\"LLM Classification: {answer.content.strip()}\")\n",
        "    print(f\"Actual Label: {actual_activity}\")\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ4ZFNfWx-y2"
      },
      "source": [
        "## Few Shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqUAJyw8x-y3",
        "outputId": "5bc49f26-61a2-4969-e0f0-e31ad1ba5106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 30\n",
            "LLM Classification: Based on the provided data, I'll classify the new accelerometer data into the correct human activity.\n",
            "\n",
            "After analyzing the patterns and similarities between the new data and the training data, I predict that the new data belongs to:\n",
            "\n",
            "Label: 5\n",
            "Actual Label: 5\n",
            "Decision Tree Classification: 5\n",
            "\n",
            "==================================================\n",
            "\n",
            "Index: 45\n",
            "LLM Classification: Based on the provided data, I'll classify the new accelerometer data into the correct human activity.\n",
            "\n",
            "After analyzing the patterns and similarities between the new data and the provided training data, I predict that the new data belongs to:\n",
            "\n",
            "Label: 5\n",
            "Actual Label: 4\n",
            "Decision Tree Classification: 4\n",
            "\n",
            "==================================================\n",
            "\n",
            "Index: 60\n",
            "LLM Classification: A classification task!\n",
            "\n",
            "After analyzing the provided data, I'll try to classify the new accelerometer data into the correct human activity.\n",
            "\n",
            "Here's the classification:\n",
            "\n",
            "Label: 5\n",
            "\n",
            "My reasoning is based on the similarity of the new data to the existing data with Label 5. Specifically, the values in the new data are closest to those in the data with Label 5 in terms of magnitude and pattern.\n",
            "Actual Label: 6\n",
            "Decision Tree Classification: 6\n",
            "\n",
            "==================================================\n",
            "\n",
            "Index: 75\n",
            "LLM Classification: Based on the provided data, I'll perform a classification using a simple k-Nearest Neighbors (k-NN) algorithm.\n",
            "\n",
            "After calculating the distances between the new data point and the existing data points, I get the following nearest neighbors:\n",
            "\n",
            "1. Data: 47    -0.978596\n",
            "439   -0.997009\n",
            "223    0.246977\n",
            "524   -1.000000\n",
            "427   -0.901140\n",
            "355   -0.947831\n",
            "237   0.236799\n",
            "172    0.953171\n",
            "85    -0.944050\n",
            "532   -0.981878\n",
            "Label: 5\n",
            "\n",
            "2. Data: 47    -0.996357\n",
            "439   -0.998344\n",
            "223    0.530063\n",
            "524   -1.000000\n",
            "427   -0.718460\n",
            "355   -0.919587\n",
            "237   -0.279982\n",
            "172    0.942514\n",
            "85    -0.881341\n",
            "532   -0.191130\n",
            "Label: 4\n",
            "\n",
            "3. Data: 47    -0.967967\n",
            "439   -0.940027\n",
            "223    0.365411\n",
            "524   -0.904762\n",
            "427   -0.534525\n",
            "355   -0.627422\n",
            "237   -0.310420\n",
            "172    0.666132\n",
            "85    -0.659056\n",
            "532   -0.973435\n",
            "Label: 2\n",
            "\n",
            "Since two out of the three nearest neighbors have a label of 4 and 5, I'll predict the label as:\n",
            "\n",
            "Label: 5\n",
            "Actual Label: 6\n",
            "Decision Tree Classification: 6\n",
            "\n",
            "==================================================\n",
            "\n",
            "Index: 90\n",
            "LLM Classification: A classification task!\n",
            "\n",
            "After analyzing the provided data, I'll use a simple k-Nearest Neighbors (k-NN) algorithm to classify the new accelerometer data into one of the five human activities.\n",
            "\n",
            "Here's the classification result:\n",
            "\n",
            "Label: 3\n",
            "\n",
            "The new data is most similar to the data with Label: 3.\n",
            "Actual Label: 1\n",
            "Decision Tree Classification: 1\n",
            "\n",
            "==================================================\n",
            "\n",
            "Index: 105\n",
            "LLM Classification: Based on the provided data, I'll classify the new accelerometer data into the correct human activity.\n",
            "\n",
            "After analyzing the patterns and similarities between the new data and the training data, I predict that the new data belongs to:\n",
            "\n",
            "Label: 2\n",
            "Actual Label: 1\n",
            "Decision Tree Classification: 1\n",
            "\n",
            "==================================================\n",
            "\n",
            "Index: 120\n",
            "LLM Classification: A classification task!\n",
            "\n",
            "After analyzing the provided data, I'll try to classify the new accelerometer data into the correct human activity.\n",
            "\n",
            "Here's the classification:\n",
            "\n",
            "Label: 3\n",
            "\n",
            "My reasoning is based on the similarity of the new data to the existing data with Label 3. Specifically, I looked at the patterns and ranges of the values in each dimension, and the new data seems to match the characteristics of the data with Label 3.\n",
            "\n",
            "Please let me know if I'm correct or not!\n",
            "Actual Label: 3\n",
            "Decision Tree Classification: 3\n",
            "\n",
            "==================================================\n",
            "\n",
            "Index: 135\n",
            "LLM Classification: Based on the provided data, I'll try to classify the new accelerometer data into the correct human activity.\n",
            "\n",
            "After analyzing the patterns and similarities between the given data and the new data, I'm going to take a prediction.\n",
            "\n",
            "Label: 2\n",
            "Actual Label: 2\n",
            "Decision Tree Classification: 2\n",
            "\n",
            "==================================================\n",
            "\n",
            "Index: 150\n",
            "LLM Classification: A classification task!\n",
            "\n",
            "After analyzing the provided data, I'll try to classify the new accelerometer data into the correct human activity.\n",
            "\n",
            "Here's the classification:\n",
            "\n",
            "Label: 3\n",
            "\n",
            "My reasoning is based on the similarity of the new data to the existing data with Label: 3. The patterns and values of the new data seem to match closely with the data in the third sample, which has a Label: 3.\n",
            "\n",
            "Please let me know if I'm correct or not!\n",
            "Actual Label: 2\n",
            "Decision Tree Classification: 2\n",
            "\n",
            "==================================================\n",
            "\n",
            "Index: 165\n",
            "LLM Classification: A classification task!\n",
            "\n",
            "After analyzing the provided data, I'll try to classify the new accelerometer data into the correct human activity.\n",
            "\n",
            "Here's the classification:\n",
            "\n",
            "Label: 5\n",
            "\n",
            "My reasoning is based on the similarity of the new data to the existing data with Label 5. Specifically, I looked at the patterns of values in each column and noticed that the new data has a similar distribution of values to the data with Label 5.\n",
            "\n",
            "Please let me know if this classification is correct or not!\n",
            "Actual Label: 5\n",
            "Decision Tree Classification: 5\n",
            "\n",
            "==================================================\n",
            "\n",
            "Decision Tree Classifications for Test Sample Indexes: [5, 4, 6, 6, 1, 1, 3, 2, 2, 5]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# Define the extract_label function\n",
        "def extract_label(llm_response):\n",
        "    \"\"\"Extract the predicted label from the LLM response.\"\"\"\n",
        "    label_match = re.search(r'(?i)label: (\\d+)', llm_response)  # The '(?i)' makes the search case-insensitive\n",
        "    if label_match:\n",
        "        return int(label_match.group(1))\n",
        "    return None\n",
        "\n",
        "# Function to get a random subset of row data\n",
        "def get_random_data_subset(row_data, subset_size=10):\n",
        "    \"\"\"Returns a random subset of 'subset_size' elements from a row.\"\"\"\n",
        "    return row_data.sample(n=subset_size, random_state=1)\n",
        "\n",
        "# Prepare few-shot training examples using a small subset of each row\n",
        "few_shot_training_data = []\n",
        "for idx in indexes:\n",
        "    # Select a random subset of the row\n",
        "    subset_of_data = get_random_data_subset(X_train.iloc[idx])\n",
        "    data_string = subset_of_data.to_string()\n",
        "    true_label = y_train.iloc[idx].values[0]\n",
        "    few_shot_training_data.append(f\"Data: {data_string}\\nLabel: {true_label}\")\n",
        "\n",
        "# Concatenate the few-shot examples for the prompt\n",
        "few_shot_input_prompt = \"\\n\\n\".join(few_shot_training_data)\n",
        "\n",
        "# Initialize the classifier\n",
        "decision_tree_clf = DecisionTreeClassifier()\n",
        "decision_tree_clf.fit(X_train, y_train)\n",
        "\n",
        "# Lists to store results\n",
        "llm_classification_predictions = []\n",
        "decision_tree_classifications = []\n",
        "actual_activity_labels = []\n",
        "\n",
        "# Test the model on new data\n",
        "test_sample_indexes = [30, 45, 60, 75, 90, 105, 120, 135, 150, 165]\n",
        "\n",
        "for test_idx in test_sample_indexes:\n",
        "    # Select a random subset of the test row\n",
        "    test_data_subset = get_random_data_subset(X_test.iloc[test_idx])\n",
        "    test_data_string = test_data_subset.to_string()\n",
        "    classification_query = (f\"{few_shot_input_prompt}\\n\\n\"\n",
        "                            f\"Classify the following accelerometer data into the correct human activity.\\n\\n\"\n",
        "                            f\"Data: {test_data_string}\\n\\n\"\n",
        "                            \"Please provide the classification in the following format:\\n\"\n",
        "                            \"Label: <predicted_label>\")\n",
        "\n",
        "    # Initialize and use the language model\n",
        "    language_model_name = \"llama3-70b\"  # Model name\n",
        "    llm_model = ChatGroq(model=groq_models[language_model_name], api_key=Groq_token, temperature=0)\n",
        "    llm_output = llm_model.invoke(classification_query)\n",
        "\n",
        "    # Extract the LLM prediction\n",
        "    llm_predicted_label = extract_label(llm_output.content.strip())\n",
        "\n",
        "    # Store LLM prediction and actual label\n",
        "    llm_classification_predictions.append(llm_predicted_label)\n",
        "    actual_activity_labels.append(y_test.iloc[test_idx].values[0])\n",
        "\n",
        "    # Decision Tree prediction\n",
        "    decision_tree_predicted_label = decision_tree_clf.predict([X_test.iloc[test_idx]])[0]\n",
        "    decision_tree_classifications.append(decision_tree_predicted_label)\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Index: {test_idx}\")\n",
        "    print(f\"LLM Classification: {llm_output.content.strip()}\")\n",
        "    print(f\"Actual Label: {y_test.iloc[test_idx].values[0]}\")\n",
        "    print(f\"Decision Tree Classification: {decision_tree_predicted_label}\")\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Now, decision_tree_classifications contains all the predictions for the indices in test_sample_indexes\n",
        "print(\"Decision Tree Classifications for Test Sample Indexes:\", decision_tree_classifications)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm_classification_predictions)\n",
        "print(decision_tree_classifications)\n",
        "print(actual_activity_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6dr1Hpw5mlh",
        "outputId": "44173fb5-938b-4439-ce74-1cb52f9d540c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 5, 5, 5, 2, 5, 5, 4, 5, 2]\n",
            "[5, 5, 4, 6, 1, 6, 6, 5, 5, 3]\n",
            "[5, 5, 4, 6, 1, 6, 6, 5, 5, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP_BVT2wx-y3",
        "outputId": "24b590a6-77b1-406e-d5c2-e8e2967bbcd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few-Shot Learning Accuracy: 0.40\n",
            "Decision Tree Accuracy: 0.90\n"
          ]
        }
      ],
      "source": [
        "# Convert lists to numpy arrays for easier calculation\n",
        "llm_predictions = np.array(llm_classification_predictions)\n",
        "decision_tree_predictions = np.array(decision_tree_classifications)\n",
        "actual_labels = np.array(actual_activity_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "def calculate_accuracy(predictions, actuals):\n",
        "    \"\"\"Calculate the accuracy of predictions compared to actual labels.\"\"\"\n",
        "    correct_predictions = np.sum(predictions == actuals)\n",
        "    accuracy = correct_predictions / len(actuals)\n",
        "    return accuracy\n",
        "\n",
        "# Calculate accuracies\n",
        "llm_accuracy = calculate_accuracy(llm_predictions, actual_labels)\n",
        "decision_tree_accuracy = calculate_accuracy(decision_tree_predictions, actual_labels)\n",
        "\n",
        "# Print results\n",
        "print(f\"Few-Shot Learning Accuracy: {llm_accuracy:.2f}\")\n",
        "print(f\"Decision Tree Accuracy: {decision_tree_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions"
      ],
      "metadata": {
        "id": "m84S51opFYvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qualitatively demonstrate the performance of Few-Shot Learning with Zero-Shot Learning. Which method performs better? Why?"
      ],
      "metadata": {
        "id": "gZp08qFGFoYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Qualitative Comparison: Few-Shot Learning vs. Zero-Shot Learning\n",
        "Few-Shot Learning: In your implementation, Few-Shot Learning involves providing the model with a small subset of labeled examples before making a prediction. This method gives the model a contextual understanding of the task by showcasing how similar data points were classified. In the example, the model was given some training examples and then asked to classify new data based on these few examples. Despite the context, the model's performance in your test showed a moderate accuracy (40%).\n",
        "\n",
        "Zero-Shot Learning: If you were to apply Zero-Shot Learning, the model would be asked to classify the new data without any labeled examples or prior context specific to the task at hand. This approach typically relies on the model's pre-trained knowledge and general understanding of language and tasks. Zero-Shot Learning might work well in tasks with clearly defined labels and well-understood context, but it could struggle in domain-specific applications like HAR, where understanding nuanced differences between activities is crucial.\n",
        "\n",
        "Performance Comparison: In your scenario, Few-Shot Learning performs better than Zero-Shot Learning would likely perform. The key advantage of Few-Shot Learning is that it offers the model some guidance by providing a few examples, improving its ability to make informed predictions. Zero-Shot Learning, on the other hand, would lack the necessary context and likely result in lower accuracy due to the specific and complex nature of human activity recognition from accelerometer data"
      ],
      "metadata": {
        "id": "CIWkRrJsFpvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantitatively compare the accuracy of Few-Shot Learning with Decision Trees (You may use a subset of the test set if you encounter rate-limiting issues). Which method performs better? Why?"
      ],
      "metadata": {
        "id": "fWCxMmGXFvN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few-Shot Learning Accuracy: Your implementation shows an accuracy of 40% for Few-Shot Learning.\n",
        "Decision Tree Accuracy: The Decision Tree model achieved a higher accuracy of 90%.\n",
        "\n",
        "Comparison:\n",
        "\n",
        "The Decision Tree clearly outperforms the Few-Shot Learning model in this scenario. This is likely because the Decision Tree model is trained directly on the HAR dataset, which contains specific patterns and correlations that are highly relevant to the task. Decision Trees can effectively model the complex decision boundaries required for accurate classification in this context.\n",
        "Few-Shot Learning, while useful for providing flexibility in new or dynamic environments, is not as effective here due to its reliance on very limited data and the LLM's general understanding rather than task-specific training.\n",
        "\n",
        "Limitations of Zero-Shot and Few-Shot Learning in HAR Classification\n",
        "Zero-Shot Learning:\n",
        "\n",
        "Lack of Task-Specific Context: Zero-Shot Learning depends heavily on the model's pre-existing knowledge, which may not cover the specific nuances of the task (e.g., differentiating between subtle movements in HAR).\n",
        "Ambiguity in Label Interpretation: Without examples, the model may misinterpret the labels or fail to recognize the distinct features that separate one activity from another.\n",
        "Few-Shot Learning:\n",
        "\n",
        "Limited Example Scope: Few-Shot Learning is constrained by the small number of examples, which may not capture the full variability of the data (e.g., different intensities of the same activity).\n",
        "Potential Overfitting to Provided Examples: The model might overfit to the small subset of examples, making it less generalizable to unseen data, especially in cases where the subset is not representative.\n",
        "Conclusion: While Few-Shot Learning offers some advantages over Zero-Shot Learning by providing a minimal amount of context, both approaches have limitations in highly specific tasks like HAR, where models trained directly on the task-relevant dataset (like the Decision Tree in your case) generally perform better."
      ],
      "metadata": {
        "id": "meOu53C_FdT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part D\n",
        "\n",
        "What does the model classify when given input from an entirely new activity that it hasn't seen before?"
      ],
      "metadata": {
        "id": "7zFTpo9uBNMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Has not seen test data before we will be testing on one of the indices"
      ],
      "metadata": {
        "id": "mzKDnyAyBdvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_subset = get_random_data_subset(X_test.iloc[1])\n",
        "test_data_string = test_data_subset.to_string()\n",
        "classification_query = (f\"{few_shot_input_prompt}\\n\\n\"\n",
        "                        f\"Classify the following accelerometer data into the correct human activity.\\n\\n\"\n",
        "                        f\"Data: {test_data_string}\\n\\n\"\n",
        "                        \"Please provide the classification in the following format:\\n\"\n",
        "                        \"Label: <predicted_label>\")\n",
        "\n",
        "# Initialize and use the language model\n",
        "language_model_name = \"llama3-70b\"  # Model name\n",
        "llm_model = ChatGroq(model=groq_models[language_model_name], api_key=Groq_token, temperature=0)\n",
        "llm_output = llm_model.invoke(classification_query)\n",
        "\n",
        "# Extract the LLM prediction\n",
        "llm_predicted_label = extract_label(llm_output.content.strip())\n",
        "\n",
        "# Store LLM prediction and actual label\n",
        "llm_classification_predictions.append(llm_predicted_label)\n",
        "actual_activity_labels.append(y_test.iloc[1].values[0])\n",
        "print(f\"Index: {1}\")\n",
        "print(f\"LLM Classification: {llm_output.content.strip()}\",activity_labels[llm_predicted_label])\n",
        "print()\n",
        "print(f\"Actual Label: {y_test.iloc[1].values[0]}\",activity_labels[llm_predicted_label])\n",
        "# print(activity_labels[llm_predicted_label])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71kR-2zCBX6f",
        "outputId": "8acc3278-2c39-4be0-bec0-a55cb91261c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 1\n",
            "LLM Classification: Based on the provided data, I'll classify the new accelerometer data into the correct human activity.\n",
            "\n",
            "After analyzing the patterns and similarities between the new data and the training data, I predict that the new data belongs to:\n",
            "\n",
            "Label: 5 STANDING\n",
            "\n",
            "Actual Label: 5 STANDING\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part E\n",
        "\n",
        "Test the model with random data (ensuring the data has the same dimensions and range as the previous input) and report the results."
      ],
      "metadata": {
        "id": "oDD2VDS9EWNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the maximum and minimum values for each column\n",
        "max_values = X_train.max()\n",
        "min_values = X_train.min()\n",
        "\n",
        "# print(\"Maximum values for each column:\")\n",
        "# print(max_values)\n",
        "# print(\"\\nMinimum values for each column:\")\n",
        "# print(min_values)\n",
        "import numpy as np\n",
        "\n",
        "# Generate a random vector\n",
        "random_vector = np.random.uniform(low=min_values, high=max_values)\n",
        "\n",
        "print(\"\\nRandom vector:\")\n",
        "print(random_vector)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9gyr3qlCXDe",
        "outputId": "84ee7560-213e-468b-af7c-2e0141a440d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random vector:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_string = random_vector\n",
        "classification_query = (f\"{few_shot_input_prompt}\\n\\n\"\n",
        "                        f\"Classify the following accelerometer data into the correct human activity.\\n\\n\"\n",
        "                        f\"Data: {test_data_string}\\n\\n\"\n",
        "                        \"Please provide the classification in the following format:\\n\"\n",
        "                        \"Label: <predicted_label>\")\n",
        "\n",
        "# Initialize and use the language model\n",
        "language_model_name = \"llama3-70b\"  # Model name\n",
        "llm_model = ChatGroq(model=groq_models[language_model_name], api_key=Groq_token, temperature=0)\n",
        "llm_output = llm_model.invoke(classification_query)\n",
        "\n",
        "# Extract the LLM prediction\n",
        "llm_predicted_label = extract_label(llm_output.content.strip())\n",
        "\n",
        "# Store LLM prediction and actual label\n",
        "llm_classification_predictions.append(llm_predicted_label)\n",
        "actual_activity_labels.append(y_test.iloc[1].values[0])\n",
        "# print(f\"Index: {1}\")\n",
        "print(f\"LLM Classification: {llm_output.content.strip()}\",activity_labels[llm_predicted_label])\n",
        "# print(activity_labels[llm_predicted_label])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwo3aEs3EOwm",
        "outputId": "6a4e8da1-254d-446f-8c57-d094c57de359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM Classification: A classification task!\n",
            "\n",
            "After analyzing the provided accelerometer data, I'll do my best to classify it into one of the human activity labels.\n",
            "\n",
            "**Label: 5**\n",
            "\n",
            "Please note that this classification is based on a simple analysis of the data and might not be accurate. A more robust approach would involve training a machine learning model on a dataset of labeled accelerometer data to learn patterns and relationships between the data and the corresponding human activities. STANDING\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use the Few-Shot prompting method using UCI-HAR dataset to predict the activities that you performed. Ensure that both your examples and test query undergo similar preprocessing. How did the model perform?"
      ],
      "metadata": {
        "id": "JgfsEO34XIaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('output_X.csv')\n",
        "df1 = pd.read_csv('output_Y.csv')\n",
        "df = pd.concat([df, df1], axis=1)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk-d9kLdE0RN",
        "outputId": "2a336fe5-542b-442a-f0e8-9ebc350ea0c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         accx    accy    accz           y_train\n",
            "0      0.9883 -0.0447  0.0562  WALKING_UPSTAIRS\n",
            "1      0.9854 -0.0481  0.0501  WALKING_UPSTAIRS\n",
            "2      0.9956 -0.0640  0.0007  WALKING_UPSTAIRS\n",
            "3      1.0039 -0.0706 -0.0000  WALKING_UPSTAIRS\n",
            "4      1.0130 -0.0623  0.0090  WALKING_UPSTAIRS\n",
            "...       ...     ...     ...               ...\n",
            "28282  1.2234 -0.2779  0.0058           WALKING\n",
            "28283  1.1741 -0.1879  0.0178           WALKING\n",
            "28284  0.9345  0.0812  0.0816           WALKING\n",
            "28285  0.8160  0.0433  0.1530           WALKING\n",
            "28286  0.8697  0.0125  0.1740           WALKING\n",
            "\n",
            "[28287 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the datasets\n",
        "df_X = pd.read_csv('output_X.csv')\n",
        "df_Y = pd.read_csv('output_Y.csv')\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Optionally, verify the shapes of the datasets\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24qrvEGRXVD5",
        "outputId": "8bd9cc76-2624-4f5f-ebb2-3d40fb46f2cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (22629, 3), y_train shape: (22629, 1)\n",
            "X_test shape: (5658, 3), y_test shape: (5658, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Define a mapping from activity labels to human-readable activity names\n",
        "activity_labels = {\n",
        "    \"WALKING\": 1,\n",
        "    \"WALKING_UPSTAIRS\": 2,\n",
        "    \"WALKING_DOWNSTAIRS\": 3,\n",
        "    \"SITTING\": 4,\n",
        "    \"STANDING\": 5,\n",
        "    \"LAYING\": 6\n",
        "}\n",
        "\n",
        "# Sample a few random examples from the training set for few-shot learning\n",
        "few_shot_examples = []\n",
        "for _ in range(3):  # Choose how many examples you'd like to include\n",
        "    random_index = random.randint(0, len(X_train) - 1)\n",
        "    example_data = X_train.iloc[random_index].values\n",
        "    example_label = y_train.iloc[random_index].values[0]\n",
        "    few_shot_examples.append((example_data, activity_labels[example_label]))\n",
        "\n",
        "# Construct the few-shot input prompt\n",
        "few_shot_input_prompt = \"You are an AI trained to classify human activities based on accelerometer data.\\n\"\n",
        "few_shot_input_prompt += \"Here are some examples of how accelerometer data is classified into specific human activities:\\n\\n\"\n",
        "\n",
        "for i, (data, label) in enumerate(few_shot_examples):\n",
        "    few_shot_input_prompt += f\"Example {i+1}:\\n\"\n",
        "    few_shot_input_prompt += f\"Data: {list(data)}\\n\"\n",
        "    few_shot_input_prompt += f\"Label: {label}\\n\\n\"\n",
        "\n",
        "few_shot_input_prompt += \"Now, classify the following accelerometer data into the correct human activity.\\n\\n\"\n"
      ],
      "metadata": {
        "id": "wb4nL24VXZXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming the necessary imports and definitions are already in place\n",
        "llm_classification_predictions = []\n",
        "actual_activity_labels = []\n",
        "\n",
        "# Iterate over each row in X_test\n",
        "for index, row in X_test.iterrows():\n",
        "    # Prepare the data string from the row\n",
        "    test_data_string = list(row.values)\n",
        "\n",
        "    # Construct the classification query\n",
        "    classification_query = (f\"{few_shot_input_prompt}\\n\\n\"\n",
        "                            f\"Classify the following accelerometer data into the correct human activity.\\n\\n\"\n",
        "                            f\"Data: {test_data_string}\\n\\n\"\n",
        "                            \"Please provide the classification in the following format:\\n\"\n",
        "                            \"Label: <predicted_label>\")\n",
        "\n",
        "    # Initialize and use the language model\n",
        "    language_model_name = \"llama3-70b\"  # Model name\n",
        "    llm_model = ChatGroq(model=groq_models[language_model_name], api_key=Groq_token, temperature=0)\n",
        "    llm_output = llm_model.invoke(classification_query)\n",
        "\n",
        "    # Extract the LLM prediction\n",
        "    llm_predicted_label = extract_label(llm_output.content.strip())\n",
        "\n",
        "    # Store LLM prediction and actual label\n",
        "    llm_classification_predictions.append(llm_predicted_label)\n",
        "\n",
        "    # Use index alignment to get the correct label\n",
        "    actual_activity_label = y_test.iloc[index] if index < len(y_test) else None\n",
        "    actual_activity_labels.append(actual_activity_label.values[0] if actual_activity_label is not None else None)\n",
        "\n",
        "# Convert lists to numpy arrays for plotting\n",
        "predicted_values = np.array(llm_classification_predictions)\n",
        "actual_values = np.array(actual_activity_labels)\n",
        "\n",
        "# Step 3: Plot a Bar Graph\n",
        "\n",
        "# Get unique activity labels and their counts\n",
        "unique_labels, actual_counts = np.unique(actual_values, return_counts=True)\n",
        "_, predicted_counts = np.unique(predicted_values, return_counts=True)\n",
        "\n",
        "# Plotting the bar graph\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(unique_labels))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(index, actual_counts, bar_width, label='Actual', color='b')\n",
        "plt.bar(index + bar_width, predicted_counts, bar_width, label='Predicted', color='r')\n",
        "\n",
        "plt.xlabel('Activity Labels')\n",
        "plt.ylabel('Counts')\n",
        "plt.title('Comparison of Actual and Predicted Activity Labels')\n",
        "plt.xticks(index + bar_width / 2, [activity_labels[label] for label in unique_labels])\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "8VLKPIbdZG9X",
        "outputId": "09a5140c-74ae-4d46-945d-90df97bcc5d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InternalServerError",
          "evalue": "Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-6601bca52de3>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mlanguage_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"llama3-70b\"\u001b[0m  \u001b[0;31m# Model name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mllm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatGroq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroq_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlanguage_model_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGroq_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mllm_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Extract the LLM prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m         return cast(\n\u001b[1;32m    275\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    277\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    775\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         flattened_outputs = [\n\u001b[1;32m    635\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[list-item]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                 results.append(\n\u001b[0;32m--> 623\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    624\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    846\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         }\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    285\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"\n\u001b[0;32m--> 287\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0;34m\"/openai/v1/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1242\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m         )\n\u001b[0;32m-> 1244\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 936\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    937\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1025\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1074\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mInternalServerError\u001b[0m: Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u_0WJ2D5aRUi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}